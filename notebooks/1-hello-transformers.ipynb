{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1 - Hello Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Dear Amazon, last week I ordered an Optimus Prime action figure\n",
    "from your online store in Germany. Unfortunately, when I opened the package,\n",
    "I discovered to my horror that I had been sent an action figure of Megatron\n",
    "instead! As a lifelong enemy of the Decepticons, I hope you can understand my\n",
    "dilemma. To resolve the issue, I demand an exchange of Megatron for the\n",
    "Optimus Prime figure I ordered. Enclosed are copies of my records concerning\n",
    "this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline('text-classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text-Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "outputs = classifer(text)\n",
    "\n",
    "pd.DataFrame(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tagger = pipeline('near',\n",
    "                      aggregation_strategy='simple')\n",
    "\n",
    "outputs = ner_tagger(text)\n",
    "\n",
    "pd.DataFrame(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Answering (Q/A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = pipeline('question-answering')\n",
    "\n",
    "question = 'What does the customer want?'\n",
    "\n",
    "outputs = reader(question=question,\n",
    "                 context=text)\n",
    "\n",
    "pd.DataFrame(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline('summarization')\n",
    "\n",
    "outputs = summarizer(text,\n",
    "                     max_length=45,\n",
    "                     clean_up_tokenization_spaces=True)\n",
    "\n",
    "print(outputs[0]['summary_text'])\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = pipeline('translation_en_to_de',\n",
    "                      model='Helsinki-NLP/opus-mt-en-de')\n",
    "\n",
    "outputs = translator(text, \n",
    "                     clean_up_tokenization_spaces=True,\n",
    "                     min_length=100)\n",
    "\n",
    "print(outputs[0]['translation_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline('text-generation')\n",
    "\n",
    "response = 'Dear Bumblebee, I am sorry to hear that your order was mixed up.'\n",
    "\n",
    "prompt = text + '\\n\\nCustomer service response:\\n' + response\n",
    "\n",
    "outputs = generator(prompt, max_length=200)\n",
    "\n",
    "print(outputs[0]['generated_text'])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
